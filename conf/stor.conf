########################### Common ###########################
[COMMON]
    env:JAVA_HOME = /usr/java/jdk1.8.0_112

####################### Zookeeper Common #####################
[ZK_COMMON]
    mounts = /dev/sdb2:/data/stor/ssd
    mkfs_cmd = mkfs.ext4
    mount_opts  = rw,noatime,seclabel,data=ordered
    package = /home/watermelon/workspace/software/zookeeper-3.4.10.tar.gz

    #these configs are for ${ZK_HOME}/conf/zoo.cfg
    cfg:dataDir=/data/stor/ssd/zk/data
    cfg:dataLogDir=/data/stor/ssd/zk/dataLog

    #these configs are for ${ZK_HOME}/bin/zkEnv.sh
    env:ZOOPIDFILE = /var/zookeeper/pid/zookeeper_server.pid
    env:ZOO_LOG_DIR= /var/zookeeper/logs

[ZK_NODES]
    192.168.100.131?myid=1 & env:JAVA_HOME = /usr/java/latest & env:ZOOPIDFILE = /tmp/zookeeper_server.pid  & env:ZOO_LOG_DIR= /tmp
    192.168.100.132?myid=2 & mounts=/dev/sdc:/data/stor/sdc & cfg:dataDir=/data/stor/sdc/zk/data & cfg:dataLogDir=/data/stor/sdc/zk/dataLog & install_path=/opt
    192.168.100.133?myid=3

########################## HDFS Common #######################
[HDFS_COMMON]
    mounts = /dev/sdc:/data/stor/hdfs/sdc,/dev/sdd:/data/stor/hdfs/sdd
    mkfs_cmd = mkfs.ext4
    mount_opts = rw,noatime,seclabel,data=ordered
    package = /home/watermelon/workspace/software/hadoop-2.8.0.tar.gz

    #these configs are for ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh
    env:HADOOP_PID_DIR=/var/hdfs/pid
    env:HADOOP_LOG_DIR=/var/hdfs/logs
    env:HADOOP_OPTS = -Xmx512m $HADOOP_OPTS
    env:HADOOP_CLIENT_OPTS = -Xmx512m $HADOOP_CLIENT_OPTS

    #these configs are for ${HADOOP_HOME}/etc/hadoop/core-site.xml
    core-site:fs.defaultFS=hdfs://stor
    core-site:hadoop.tmp.dir=/data/stor/ssd/hdfs/tmp

    #these configs are for ${HADOOP_HOME}/etc/hadoop/hdfs-site.xml
    hdfs-site:dfs.hosts.exclude =
    hdfs-site:dfs.nameservices = stor
    hdfs-site:dfs.ha.namenodes.stor = nn1,nn2
    hdfs-site:dfs.namenode.rpc-address.stor.nn1 = 192.168.100.132:8020
    hdfs-site:dfs.namenode.rpc-address.stor.nn2 = 192.168.100.133:8020
    hdfs-site:dfs.namenode.http-address.stor.nn1 = 0.0.0.0:50070
    hdfs-site:dfs.namenode.http-address.stor.nn2 = 0.0.0.0:50070
    hdfs-site:dfs.namenode.shared.edits.dir = qjournal://192.168.100.131:8485;192.168.100.132:8485;192.168.100.133:8485/stor
    hdfs-site:dfs.client.failover.proxy.provider.stor = org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
    hdfs-site:ha.zookeeper.quorum = 192.168.100.131:2181,192.168.100.132:2181,192.168.100.133:2181
    hdfs-site:dfs.journalnode.edits.dir = /data/stor/ssd/hdfs/jn
    hdfs-site:dfs.namenode.name.dir = /data/stor/ssd/hdfs/nn
    hdfs-site:dfs.datanode.data.dir = /data/stor/ssd/hdfs/dn,/data/stor/hdfs/sdc,/data/stor/hdfs/sdd
    hdfs-site:dfs.domain.socket.path = /var/hdfs/sock/dn._PORT
    hdfs-site:dfs.datanode.max.transfer.threads = 128

[HDFS_NAME_NODES]
    192.168.100.132 ? hdfs-site:dfs.namenode.name.dir = /data/stor/sdc/hdfs/nn
    192.168.100.133

[HDFS_DATA_NODES]
    192.168.100.131
    192.168.100.132?mounts=/dev/sdb:/data/stor/hdfs/sdb,/dev/sdd:/data/stor/hdfs/sdd & core-site:hadoop.tmp.dir=/data/stor/sdc/hdfs/tmp & hdfs-site:dfs.datanode.data.dir = /data/stor/sdc/hdfs/dn,/data/stor/hdfs/sdb,/data/stor/hdfs/sdd
    192.168.100.133?extra:mounts=/dev/sde:/data/stor/hdfs/sde & extra:hdfs-site:dfs.datanode.data.dir=/data/stor/hdfs/sde

[HDFS_JOURNAL_NODES]
    192.168.100.131
    192.168.100.132 ? hdfs-site:dfs.journalnode.edits.dir = /data/stor/sdc/hdfs/jn
    192.168.100.133
