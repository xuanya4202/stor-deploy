########################### Common ###########################
     [COMMON]  	
	user = root
	install_path = /usr/local
        ssh_port = 22
	  env:JAVA_HOME=/usr/java/default

[ZK_COMMON]
	user	=   	  zookeeper
#ssh_port =  55667  
mounts = 	 /dev/vda:/home/zookeeper/data/vda
	 mkfs_cmd = mkfs.ext4
        mount_opts  =  rw,noatime,attr2,inode64

	install_path = /home/zookeeper/install
	version = zookeeper-3.4.10

	#these configs will be written into ${ZK_HOME}/conf/zoo.cfg
	cfg 	 :	 tickTime = 2000  # "cfg" stands for file "zoo.cfg"
cfg:initLimit=10
	cfg	 :syncLimit=5
  	cfg: 	 dataDir=	 /home/zookeeper/data/vda/data   
  	 cfg	:	dataLogDir=    /home/zookeeper/data/vda/log   
	cfg :clientPort=2181   
        cfg:maxClientCnxns=	 300    

	#  these configs will be written into ${ZK_HOME}/bin/zkEnv.sh 
  	 env :	JAVA_HOME =  	 /usr/java/jdk1.8.0_112
	env:ZOOPIDFILE  = /home/zookeeper/run/pid
	env:	 ZOO_LOG_DIR=  /home/zookeeper/run/logs
	env	 :ZOO_LOG4J_PROP= INFO,ROLLINGFILE   #blabla comments
                                                     # for test


[ZK_NODES]
	192.168.100.131?myid=1&
	192.168.100.132?myid=2&cfg:dataDir=/home/zookeeper/data/vda/zk-test/data
	192.168.100.133?myid=3	&  cfg:dataDir=/home/zookeeper/data/vda/zk-test/data 	& cfg:dataLogDir	= /home/zookeeper/data/vda/zk-test/log   #for test


[HDFS_COMMON]
	user=hdfs
	mounts = /dev/vdb 	 :/home/hdfs/datastor/vdb  	 ,	/dev/vdc:/home/hdfs/datastor/vdc,/dev/vdd:/home/hdfs/datastor/vdd
	 mkfs_cmd = mkfs.xfs -f -i size=1024
        mount_opts  =  rw,noatime,attr2,inode64,logbsize=256k,noquota

	install_path = /home/hdfs/install
	version = hadoop-2.8.0

	  env:JAVA_HOME=/usr/java/latest
	env :	 HADOOP_PID_DIR=/home/hdfs/run/pid
env:HADOOP_LOG_DIR=/home/hdfs/run/logs
	env:HADOOP_OPTS=-Xmx4096m $HADOOP_OPTS -Djava.net.preferIPv4Stack=true
	env:HADOOP_CLIENT_OPTS =	 -Xmx2048m $HADOOP_CLIENT_OPTS 


	core-site	  :  	 fs.defaultFS 	=   hdfs://storageproxy
	core-site:   io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.SnappyCodec
	core-site:	hadoop.tmp.dir = /home/hdfs/datastor/vdb/tmp

	hdfs-site   :dfs.hosts.exclude = /home/hdfs/install/hadoop-2.8.0/etc/hadoop/dfs.hosts.exclude
	hdfs-site		:dfs.nameservices = storageproxy 
	hdfs-site  	  :dfs.ha.namenodes.storageproxy = nn1,nn2
	hdfs-site  :  dfs.namenode.rpc-address.storageproxy.nn1 = 
	hdfs-site  :		dfs.namenode.rpc-address.storageproxy.nn2 = 
	hdfs-site	 :  dfs.namenode.http-address.storageproxy.nn1 = 0.0.0.0:50070 
	hdfs-site	  :  	  dfs.namenode.http-address.storageproxy.nn2 = 0.0.0.0:50070
	hdfs-site	:		dfs.namenode.shared.edits.dir = 
	hdfs-site	  :  ha.zookeeper.quorum = 
	hdfs-site:dfs.replication =2 
	hdfs-site:dfs.journalnode.edits.dir = /home/hdfs/datastor/vdb/jn
	hdfs-site:dfs.namenode.name.dir =  /home/hdfs/datastor/vdb/nn
	hdfs-site:dfs.datanode.data.dir = /home/hdfs/datastor/vdb/dn,/home/hdfs/datastor/vdc,/home/hdfs/datastor/vdd
	hdfs-site:dfs.namenode.handler.count=32
	hdfs-site:dfs.datanode.handler.count=4
	hdfs-site:dfs.domain.socket.path = /home/hdfs/run/sock/dn._PORT
	hdfs-site:dfs.client.file-block-storage-locations.timeout = 3000
	hdfs-site:dfs.datanode.max.transfer.threads = 1024

[HDFS_NAME_NODES]
	192.168.100.132?extra:mounts=/dev/vde:/home/hdfs/datastor/vde&hdfs-site:dfs.namenode.name.dir = /home/hdfs/datastor/vde/nn
	192.168.100.133

[HDFS_DATA_NODES]
	192.168.100.131
	192.168.100.132?site:dfs.datanode.data.dir=/home/hdfs/datastor/vdc
	192.168.100.133?extra:mounts=/dev/vde:/home/hdfs/datastor/vde&extra:hdfs-site:dfs.datanode.data.dir=/home/hdfs/datastor/vde

[HDFS_JOURNAL_NODES]
	192.168.100.131
	192.168.100.132
	192.168.100.133

[HDFS_ZKFC_NODES]
	192.168.100.131
